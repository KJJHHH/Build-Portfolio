{"cells":[{"cell_type":"markdown","metadata":{},"source":["# Setting and Data"]},{"cell_type":"markdown","metadata":{},"source":["### Lib pip/ Colab Operation\n","```do not run if not in colab```"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["!pip install optuna\n","\"\"\"\n","# mount\n","from google.colab import drive\n","drive.mount('/content/drive')\n","# path\n","os.chdir('/content/drive/MyDrive/portfolio/data')\n","import sys\n","sys.path.append(sys.path[0] + f\"/drive/MyDrive/portfolio\") # current path + ~\n","\"\"\""]},{"cell_type":"markdown","metadata":{},"source":["### Lib import"]},{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[],"source":["%load_ext autoreload\n","%autoreload 2'\n","# Preprocessing\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import mean_squared_error\n","import numpy as np\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","# other\n","import os, copy, math\n","import gc, pickle, warnings\n","warnings.filterwarnings('ignore')\n","\n","# -----------------------------------------------\n","from train import summary\n","from models.ensmeble import ensemble"]},{"cell_type":"markdown","metadata":{},"source":["### Load Data\n","- Three Types of Data for Different Industries\n","    - Automobile (mainly this)\n","    - Semi Conduntor: not suitable enough? it is the flourishing rapidly grow industry\n","    - Panels"]},{"cell_type":"code","execution_count":2,"metadata":{},"outputs":[],"source":["industry = \"automobile\"\n","\n","# Colab get data\n","\"\"\"\n","with open(f\"{sys.path[-1]}/data/{industry}/data4model.pickle\", \"rb\") as f:\n","    data = pickle.load(f)\n","\"\"\"\n","# PC get data\n","with open(f\"data/{industry}/data4model.pickle\", \"rb\") as f:\n","    data = pickle.load(f)\n","\n","# preprocess; most preprocess are done in data file, eg. standardise, ...\n","data = data.reset_index()\n","data[\"ymd\"] = pd.to_datetime(data[\"ymd\"], format=\"%Y-%m-%d\")\n","data = data.set_index([\"code\", \"ymd\"])"]},{"cell_type":"code","execution_count":7,"metadata":{},"outputs":[],"source":["# ???\n","# if pca add index. if no pca reset index. , \"open\", \"close\", \"high\", \"low\", \"Volume\""]},{"cell_type":"markdown","metadata":{},"source":["### Check Data"]},{"cell_type":"code","execution_count":3,"metadata":{},"outputs":[],"source":["# Check data\n","input_size = 89\n","model_strategy = {\n","    \"long\": 90,         # percentile\n","    \"short\": 10,        # percentile\n","    \"train_size\": 5,    # y\n","    \"test_size\": 1,     # m\n","    \"test_year\": 2021,  # start test from 2021/01\n","    \"n_trials\": 1\n","    }\n","train_size = model_strategy[\"train_size\"]\n","test_size = model_strategy[\"test_size\"]\n","portfolio = summary(input_size) # input_size\n","train_start, train_end, test_end = portfolio.traintest_period(None, \n","                                                    model_strategy[\"test_year\"], \n","                                                    None, \n","                                                    train_size, test_size, \"begin\") \n","\n","data_rolling = portfolio.Xy(data, train_start, train_end, test_end)"]},{"cell_type":"markdown","metadata":{},"source":["# Train"]},{"cell_type":"markdown","metadata":{},"source":["### Functions"]},{"cell_type":"code","execution_count":4,"metadata":{},"outputs":[],"source":["# ///////////////////////////////////////////////////////////////////////////////////////////\n","# nn: nn_{param['n_trials']}trials\n","# linear: linear\n","# update model name for NN to add trials in file name\n","# Need to update file name with ls_decision\n","def store_result(industry, model, model_strategy, performance):\n","    performance_rolling, loss_rolling, rplsw_rolling, market_rolling = performance\n","    if model == \"neural network\":\n","        model_ = f\"{model} with number of trials {model_strategy['n_trials']}\"\n","    else:\n","        model_ = model\n","\n","    # store result\n","    with open(\n","        f\"result/{industry}/result_train{model_strategy['train_size']}test{model_strategy['test_size']}/{model_}.pickle\", \n","        \"wb\") as f:\n","        pickle.dump([performance_rolling, loss_rolling, rplsw_rolling, market_rolling], f)\n","\n","def load_result(industry, model, model_strategy): # haven't test this function\n","    if model == \"neural network\":\n","        model_ = f\"{model} with number of trials {model_strategy['n_trials']}\"\n","    else:\n","        model_ = model\n","        \n","    # load result\n","    with open(\n","        f\"result/{industry}/result_train{model_strategy['train_size']}test{model_strategy['test_size']}/{model_}.pickle\", \n","        \"rb\") as f:\n","        a = pickle.load(f)\n","    performance_rolling, loss_rolling, rplsw_rolling, market_rolling = a\n","    return performance_rolling, loss_rolling, rplsw_rolling, market_rolling\n","# ///////////////////////////////////////////////////////////////////////////////////////////\n","\n","def params_setting(model):\n","    if model == \"linear\":\n","        params = {\n","            # \"normalize\": True        \n","        }\n","    elif model == \"decision tree\":\n","        params = { # decision tree\n","            \"criterion\": ['friedman_mse', 'absolute_error', 'poisson', 'squared_error'],  # squared_e defaulted\n","            \"max_depth\": [None, 5, 10], # \n","            \"min_samples_split\": [5, 10],\n","        }\n","    elif model == \"random forest\":\n","        params = {\n","            'n_estimators': [20], # 50, 100, \n","            'max_depth': [None, 10, 20],\n","            'min_samples_split': [2, 5, 10],\n","            'min_samples_leaf': [1, 2, 4],\n","            'max_features': ['auto', 'sqrt', 'log2']\n","        }\n","    elif model == \"xgboost\":\n","        params = {\n","            \"learning_rate\": [0.01, 0.1, 0.001],\n","            \"n_estimators\": [5, 10, 20, 30], # original set: [5, 10, 20, 30]\n","            \"max_depth\": [None, 3, 10, 5],\n","            \"min_child_weight\": [1, 2, 3] \n","        }\n","    elif model == \"svm\": \n","        params = {\n","            \"C\": [0.1, 1, 10],\n","            \"kernel\": [ \"rbf\"], # \"poly\", \"linear\",\n","            \"gamma\": [\"scale\", \"auto\", 0.1, 1]\n","        }\n","    elif model == \"neural network\": # tune in random, so only set the n_trials of tune\n","        params = {\n","            \"batch_size\": 25,\n","            }\n","    elif model == \"elastic net\":\n","        params = {\n","            \"l1_ratio\" : np.arange(0., 1., .1),\n","            \"alpha\" : [1e-5, 1e-4, 1e-3, 1e-2, 1e-1, 1],\n","        }\n","    elif model == \"ensemble\":\n","        params = {}\n","    return params\n","\n","def decide_tune(time, tune_per_n_month = 6):\n","    tune = True if time % tune_per_n_month == 1 else True\n","    return tune\n","\n","\n","def train_store(model, model_strategy):    \n","    #########################################################################################\n","    # Setting\n","    param = params_setting(model)\n","    train_size = model_strategy[\"train_size\"]\n","    test_size = model_strategy[\"test_size\"]\n","\n","    #########################################################################################\n","    # Initialise \n","    # class summary in train.py\n","    portfolio = summary(param, model_strategy[\"n_component\"])\n","\n","    # Get train test date | if build portfolio for future: future = True\n","    future = False\n","    if future == True: \n","        # train_start, train_end, test_end, train_size(y), test_size(m)\n","        train_start, train_end, test_end = portfolio.traintest_period(\n","                                                    None,           # train_start\n","                                                    None,           # train_end\n","                                                    None,           # test end\n","                                                    train_size,     # train size\n","                                                    test_size,      # test size\n","                                                    \"begin\",        # init\n","                                                    future)         # future\n","    else: # backtest\n","        train_start, train_end, test_end = portfolio.traintest_period(\n","                                                    None, \n","                                                    model_strategy[\"test_year\"], \n","                                                    None, \n","                                                    train_size, \n","                                                    test_size, \n","                                                    \"begin\",\n","                                                    future) \n","    \n","    \n","    #########################################################################################\n","    # ROLLING PREDICTION\n","    performance_rolling = pd.DataFrame()\n","    rplsw_rolling = pd.DataFrame()\n","    market_rolling = pd.DataFrame()\n","    loss_rolling = []\n","    longshort_thres = None\n","    time = 0\n","    while True:\n","        gc.collect()\n","        print(\"=\"*80)\n","\n","        # decide if tune\n","        time += 1\n","        tune = decide_tune(time, tune_per_n_month=6)\n","        \n","        # summary in train.py\n","        portfolio = summary(param, model_strategy[\"n_component\"])\n","\n","        # data: tuple of (X_train, y_train, X_test, y_test); update data\n","        data_rolling = portfolio.Xy(\n","            data, \n","            train_start, \n","            train_end, \n","            test_end)\n","            \n","        \n","        # check sample size\n","        if data_rolling[0].shape[0] <= data_rolling[0].shape[1]:\n","            print(f\"Warning: Sample size too small -> size {data_rolling[0].shape}\")   \n","        if len(data_rolling[2].reset_index().groupby(\"ymd\").count()) != 1: \n","            print(\"/\"*70)\n","            print(\"Weird data: too many dates in test data, expect 1!\")\n","            print(data_rolling[2])\n","            break\n","        \n","        # TRAIN        \n","        if model == \"ensemble\":      # ensemble\n","            param = params_setting(model)\n","            longshort_thres = None      \n","\n","            # Comput performance  \n","                # performance: portfolio returns\n","                # rplsw: cols of [return, predicted return, long_boundary, short boundary, weight]\n","                # market: buy and hold return          \n","            performance, market, rplsw = ensemble( \n","                params_setting,\n","                data_rolling, \n","                model_strategy, \n","                longshort_thres, \n","                tune)            \n","            loss = None\n","\n","        elif model != \"ensemble\":    # other models\n","            true_predict, longshort_thres, loss = portfolio.train_lsdecision(\n","                data_rolling, \n","                model_strategy, \n","                longshort_thres, \n","                tune, \n","                )            \n","            \n","            # Comput performance\n","                # performance: portfolio returns\n","                # rplsw: cols of [return, predicted return, long_boundary, short boundary, weight]\n","                # market: buy and hold return\n","            performance, rplsw, market = portfolio.compute_ret(\n","                data_tp=true_predict,                   # data with returns and predicted returns\n","                not_short=model_strategy[\"not_short\"],  # short or not\n","                print_detail=False)                     # print long/short stocks list    \n","            \n","\n","        # store performance, rplsw, and market\n","        performance_rolling = pd.concat([performance_rolling, performance], axis=0)\n","        rplsw_rolling = pd.concat([rplsw_rolling, rplsw], axis=0)\n","        market_rolling = pd.concat([market_rolling, market], axis=0)        \n","        \n","        # print informations\n","        print(f\"train start, train end, and test end: ({train_start, train_end, test_end})\")\n","        print(f\"UPDATE DATE: {data_rolling[2].reset_index().groupby('ymd').groups.keys()}\")\n","        print(f\"params: {param}\")\n","        print(f\"perform mean: {performance_rolling['performance'].mean()}\")\n","        print(f\"market mean: {market_rolling['return'].mean()}\")\n","        \n","        # update date\n","        train_start, train_end, test_end = portfolio.traintest_period(train_start, train_end, test_end, train_size, test_size, \"update\") \n","        if test_end > max(data.reset_index()[\"ymd\"]):\n","            break\n","\n","    performance = (performance_rolling, loss_rolling, rplsw_rolling, market_rolling)\n","    store_result(industry, model, model_strategy, performance)\n","    \n","    return performance_rolling, loss_rolling, rplsw_rolling, market_rolling\n","    "]},{"cell_type":"code","execution_count":7,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["##########################################\n","new model\n","random forest\n","================================================================================\n","tuning random forest\n","Finish Tuning\n","Check sum of weight: 1.0\n","train start, train end, and test end: ((Timestamp('2016-01-01 00:00:00'), Timestamp('2020-12-30 00:00:00'), Timestamp('2021-01-30 00:00:00')))\n","UPDATE DATE: dict_keys([Timestamp('2021-01-11 00:00:00')])\n","params: {'n_estimators': [20], 'max_depth': [None, 10, 20], 'min_samples_split': [2, 5, 10], 'min_samples_leaf': [1, 2, 4], 'max_features': ['auto', 'sqrt', 'log2']}\n","perform mean: -0.0134311234095038\n","market mean: -0.05366749324357875\n","================================================================================\n","tuning random forest\n","Finish Tuning\n","Check sum of weight: 0.9999999999999999\n","train start, train end, and test end: ((Timestamp('2016-02-01 00:00:00'), Timestamp('2021-01-30 00:00:00'), Timestamp('2021-02-28 00:00:00')))\n","UPDATE DATE: dict_keys([Timestamp('2021-02-09 00:00:00')])\n","params: {'n_estimators': [20], 'max_depth': [None, 10, 20], 'min_samples_split': [2, 5, 10], 'min_samples_leaf': [1, 2, 4], 'max_features': ['auto', 'sqrt', 'log2']}\n","perform mean: -0.00821352392853954\n","market mean: -0.015715485694935187\n","================================================================================\n","tuning random forest\n","Finish Tuning\n","Check sum of weight: 1.0\n","train start, train end, and test end: ((Timestamp('2016-03-01 00:00:00'), Timestamp('2021-02-28 00:00:00'), Timestamp('2021-03-28 00:00:00')))\n","UPDATE DATE: dict_keys([Timestamp('2021-03-10 00:00:00')])\n","params: {'n_estimators': [20], 'max_depth': [None, 10, 20], 'min_samples_split': [2, 5, 10], 'min_samples_leaf': [1, 2, 4], 'max_features': ['auto', 'sqrt', 'log2']}\n","perform mean: 0.030759743057782257\n","market mean: 0.020723475670677085\n","================================================================================\n","tuning random forest\n"]}],"source":["# train the model and print something\n","models = {1: \"linear\",\n","         2: \"elastic net\",\n","         3: \"decision tree\", \n","         4: \"random forest\", \n","         5: \"xgboost\", \n","         6: \"svm\",\n","         7: \"ensemble\", \n","         8: \"neural network\",\n","         }\n","\n","model_strategy = {\n","        \"model\": None,      # \"linear\" or \"decision tree\" or \"xgboost\" or \"svm\" or \"neural network\"\n","        \"long\": 80,         # percentile\n","        \"short\": 20,        # percentile\n","        \"train_size\": 5,    # y\n","        \"test_size\": 1,     # m\n","        \"test_year\": 2021,  # start test from 2021/01\n","        \"n_trials\": 1,      # NN \n","        \"not_short\": False, # if not short == True: only do long\n","        \"ls_decision\": [\"test\", \"running\"], # long short decision [\"test\"/\"train\", \"running\"]\n","        \"n_component\": 89   # = input size | original dimension = input_size: 89\n","        }\n","\n","\n","for i in [4, 5]:\n","    model = models[i]\n","    model_strategy[\"model\"] = model\n","    print(\"##########################################\")\n","    print(\"new model\")\n","    print(model)\n","    performance_rolling, loss_rolling, rplsw_rolling, market_rolling = train_store(model, model_strategy) \n","    break      \n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["result = performance_rolling.merge(market_rolling, on=\"ymd\", how='outer')\\\n","                            .set_index([\"ymd\"])\n","result.head(3)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["market_cum_asset = np.cumprod(1 + result[\"return\"])\n","portfolio_cum_asset = np.cumprod(1 + result[\"performance\"])\n","plt.figure(figsize=(15, 6))\n","plt.plot(portfolio_cum_asset, label=\"portfolio cum ret\")\n","plt.plot(market_cum_asset, label = 'market cum ret')\n","plt.title(\"cumulative asset\") \n","plt.legend()\n","plt.show()"]}],"metadata":{"colab":{"collapsed_sections":["fgK47LewkRZM","3romliCWkTbQ","YcDFI0JpZHxw","Jyw1-cWo3M_q","dqP0p7Dp3M_w","gHlkoOwx3M_w","SrskO-fF3M_x","zJL0VM77AeoP","VWYDDxU_AkNi","kszecLXaAmDn","ZExqaiX8Asvo","yss1EeYd3M_y","RKX5DkLY3M_y","n-HtSNCV3M_z","PuFfn2pj3M_z","wVhoWqlObOkL","MxETIaXdhq95","jbvzFcXuhnkY","U8dcsAJ5JvUy","P087UBAzQ8t6","0qDfbEB_l7TG","U1WGHJ5k1Bzl","G1qtUGUT09rA","8Oco3lmpl-wf","UML-xoMG0xuz","jPeeLtK2vZAo","6r9n3AZclXxs","5tLXw4NQllH_","ad3t2US_0l_H","_z_7j8jqvePv","F9uYuqwXl8Dr","cunoqtMQmDQ0","xHYR2gC02tN2","JPzQp_NJc8M6","uJX3GqYjATkW","QYOCQzs65iCh","c3yPrIfS5k5X","mxXUcF5WRZDG","YJVoCD4B-Po9"],"gpuType":"T4","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.4"}},"nbformat":4,"nbformat_minor":0}
